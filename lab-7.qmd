---
title: "Lab 7 - API Work"
author: "Harshini Karthikeyan, Alisa Krasilnikov"
format: html
embed-resources: true
editor: source
execute: 
  echo: true
---

```{r, warning = FALSE, echo = TRUE}
#| label: load-packages
library(httr)
library(jsonlite)
library(dplyr)
library(purrr)
library(readr)
library(tidyverse)
library(leaflet)
library(knitr)
library(rnaturalearth)
library(sf)
library(rnaturalearthdata)
library(tidyjson)
#eab39c3c6fb6d4f959dbcb4ad3ad9a8205551bc1

```

```{r}
#| label: load-data
capitals_names <- read_lines("https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_name.txt")
capitals_lat_long <- read_lines("https://people.sc.fsu.edu/~jburkardt/datasets/states/state_capitals_ll.txt")
```

```{r}
#| label: dataframe-cleaning
latlon_df <- str_split(capitals_lat_long, "\\s+", simplify = TRUE) |>  
  as.data.frame() |> 
  rename(state = V1, latitude = V2, longitude = V3) |> 
  mutate(state = trimws(state))

capitals_df <- str_split(capitals_names, '"', simplify = TRUE) |>  
  as.data.frame() |> 
  rename(state = V1, capital = V2) |> 
  select(-V3) |> 
  mutate(state = trimws(state))

full_capitals_dataset <- full_join(latlon_df, capitals_df, by = "state")


full_capitals_dataset <- full_capitals_dataset |> 
  mutate(
    capital = str_remove_all(capital, '"'),
    latitude = as.numeric(latitude),
    longitude = as.numeric(longitude)
  )
```


```{r}
#| label: testing

response <- GET("https://api.g7vrd.co.uk/v1/satellite-passes/25544/51.45/-2.5833.json")

space <- response$content |> 
  rawToChar() |>  
  fromJSON()

str(space)


json_tbl <- response$content |> 
  rawToChar() |> 
  as.tbl_json()

json_tbl |>  
  spread_all() |> 
  enter_object("passes") |> 
  gather_array() |>     # if it's a JSON array
  spread_all() |> 
  select(start)
```

```{r}
#| label: API-function
get_pass_times <- function(lat, lon) {
  #Construct the API URL for the given latitude and longitude
  url <- paste0("https://api.g7vrd.co.uk/v1/satellite-passes/25544/", lat, "/", lon, ".json")
  response <- GET(url) #Call the API 

  if (status_code(response) == 200) {
    data <- fromJSON(rawToChar(response$content)) #Convert raw JSON to useable form
    
    if (!is.null(data$passes)) {
      return(head(data$passes$tca, 3)) #If passes exists in the data, extract first three pass times. Note that these are ordered descending, so it should get the earliest three times.
    }
  }

  return(rep(NA, 3))  #Return 3 NAs if unavailable
}
```


```{r}
#| label: Getting-data

capitals_with_passes <- full_capitals_dataset |> 
  mutate(pass_times = pmap(list(latitude, longitude), get_pass_times))

capitals_with_passes <- capitals_with_passes |> 
  mutate(
    #Extract up to three pass times from the lists in pass_times
    #Use map_chr to ensure each output is a character vector of length 1
    #The function checks if there is at least (number) elements in the list, if so, it extracts the (number) one, otherwise, it returns NA
    pass_time_1 = map_chr(pass_times, ~ if(length(.) >= 1) .[1] else NA), 
    pass_time_2 = map_chr(pass_times, ~ if(length(.) >= 2) .[2] else NA),
    pass_time_3 = map_chr(pass_times, ~ if(length(.) >= 3) .[3] else NA)) |>
  select(-pass_times)
```


```{r}
capitals <- ne_download(scale = "medium", type = "populated_places", category = "cultural", returnclass = "sf")


us_capitals <- capitals |>
  filter(ADM0NAME == "United States of America", FEATURECLA == "Admin-1 capital") |>
  mutate(capital = if_else(NAMEASCII == "St. Paul", "St Paul", NAMEASCII))

```

```{r}
#head(us_capitals)
#capitals_with_passes
us<-inner_join(us_capitals, capitals_with_passes, by = join_by(capital))

```


```{r}


leaflet(capitals_with_passes) |> addTiles() %>%
  addCircleMarkers(lng = capitals_with_passes$longitude, lat = us$latitude,
             popup = paste(
      "<b>", us$capital, "</b><br/>",
      "Next Three ISS Passtimes: ", as_datetime(us$pass_time_1)))

```

